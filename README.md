### Microsoft Fabric - Sales Data Ingestion Pipeline
This project demonstrates how to build a basic data ingestion pipeline using Microsoft Fabric and Dataflows Gen2, designed to ingest and transform sales data into a Lakehouse.

### Overview
In this project, you will:

Create a Microsoft Fabric workspace

Build a Lakehouse for storing data

Use Dataflows Gen2 to connect to an external CSV data source

Perform data transformations in Power Query Editor

Add a data destination (Lakehouse table)

Integrate the dataflow into a Data Pipeline

Run and validate the pipeline results in the Lakehouse

This project uses a sample CSV file hosted at:
https://raw.githubusercontent.com/MicrosoftLearning/dp-data/main/orders.csv

### Key Components
Microsoft Fabric

Lakehouse

Dataflows (Gen2)

Power Query

Data Pipeline

Power BI (optional for visualization)

### Use Case
This lab-style project simulates a simplified ETL (Extract, Transform, Load) workflow, common in enterprise analytics. It's an ideal entry point to understand how data flows into Microsoft Fabric for advanced analytics and reporting scenarios.

### Prerequisites
A Microsoft Fabric trial or licensed environment

Power BI credentials for authentication

Basic understanding of data transformation logic

### Cleanup
To remove all resources after completing the exercise:

Go to your Microsoft Fabric workspace

Open Workspace Settings

Select Remove this workspace

Confirm deletion

### Resources
Microsoft Fabric Documentation

Power Query Documentation

Source CSV File

